---
title: "TG2 - wrangling e análise exp"
author: "Arthur Giestas"
date: "23/11/2021"
output: word_document
---

```{r bibliotecas, message=FALSE, warning=FALSE}
library(dplyr)
library(tidyr)
library(stringr)
library(tidytext)
library(data.table)
library(wordcloud)
library(tm)
library(SnowballC)
library(randomForest)
library(xgboost)
library(e1071)
library(partykit)
library(pROC)
```

```{r data reading}
order_reviews_full <- read.csv("olist_order_reviews_dataset.csv", encoding = "UTF-8") %>%
  filter(grepl("2017", review_creation_date))
```

```{r composite comment}
# remove linhas sem comentários E sem título
# remove colunas desnecessárias
# acrescenta coluna com título concatenado ao texto do comentário
order_reviews <- order_reviews_full[!((order_reviews_full$review_comment_message == "") &
                                        (order_reviews_full$review_comment_title == "")),] %>%
  subset(data = order_reviews, select = c(-order_id,
                    -review_creation_date,
                    -review_answer_timestamp,
                    -review_id)) %>%
  mutate(comp_comment = str_c(review_comment_title, " ", review_comment_message))
```

```{r cleaning}
wc_db_clean <- order_reviews[,c(1, 4)]

wc_db_clean[,2] <- str_replace_all(wc_db_clean[,2], "[[:punct:]]", " ")

wc_db_clean[,2] <- gsub('[0-9]+', '', wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" nao ", " não ", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("exelente", "excelente", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("otima", "ótima", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("otimo", "ótimo", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("ótima", "ótimo", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("rápida", "rápido", wc_db_clean[,2])

# Limpeza nuvem BOM
wc_db_clean[,2] <- gsub("produtos", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("Produto", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" produto", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("produto ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" prazos", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" prazo", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" loja ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" entregue ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" tudo", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("tudo", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("Tudo", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" comprar", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" compra", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("veio", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("dentro", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("chegou", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("entrega ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("recebi ", "", wc_db_clean[,2])

# Limpeza nuvem NÃO BOM
wc_db_clean[,2] <- gsub("lannister", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub("comprei", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" dia ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" dois", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" pois", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" pra ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" fiz ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" site ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" estou ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" ser ", "", wc_db_clean[,2])
wc_db_clean[,2] <- gsub(" comprei ", "", wc_db_clean[,2])
```


```{r cv index generation}
index <- sample(1:nrow(wc_db_clean),
       0.7*nrow(wc_db_clean))
```


```{r wordcloud BOM}
db_wc_bom <- wc_db_clean[index,] %>% # conferir se não é uma filtragem redundante
  filter(review_score > 3)

corpus_wc_bom <- Corpus(VectorSource(db_wc_bom[,2])) %>%
  tm_map(removeWords, stopwords("portuguese")) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(content_transformer(tolower))

tdm <- TermDocumentMatrix(corpus_wc_bom)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=20, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r dummy variables BOM}
db_dummy_bom <- wc_db_clean

str(db_dummy_bom$review_comment_message)


for (i in 1:nrow(db_dummy_bom)) {
  
# CRIACAO DA VARIAVEL RESPOSTA (Y)
  db_dummy_bom$Y5[i] <- if_else(db_dummy_bom$review_score[i] == 5, 1, 0)
  db_dummy_bom$Y4[i] <- if_else(db_dummy_bom$review_score[i] == 4, 1, 0)
  db_dummy_bom$Y3[i] <- if_else(db_dummy_bom$review_score[i] == 3, 0, 0)
  db_dummy_bom$Y2[i] <- if_else(db_dummy_bom$review_score[i] == 2, 0, 0)
  db_dummy_bom$Y1[i] <- if_else(db_dummy_bom$review_score[i] == 1, 0, 0)
  
  db_dummy_bom$Y[i] <- 
    db_dummy_bom$Y5[i] +
    db_dummy_bom$Y4[i] +
    db_dummy_bom$Y3[i] +
    db_dummy_bom$Y2[i] + 
    db_dummy_bom$Y1[i]
  
# CRIACAO DAS VARIAVEIS DUMMIES
  db_dummy_bom$X1[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "sempre"), 1, 0)
  db_dummy_bom$X2[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "qualidade"), 1, 0)
  db_dummy_bom$X3[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "super"), 1, 0)
  db_dummy_bom$X4[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "ótimo"), 1, 0)
  db_dummy_bom$X5[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "certo"), 1, 0)
  db_dummy_bom$X6[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "muito"), 1, 0)
  db_dummy_bom$X7[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "bom"), 1, 0)
  db_dummy_bom$X8[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "entrega"), 1, 0)
  db_dummy_bom$X9[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "gostei"), 1, 0)
  db_dummy_bom$X10[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "chegou"), 1, 0)
  db_dummy_bom$X11[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "antes"), 1, 0)
  db_dummy_bom$X12[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "boa"), 1, 0)
  db_dummy_bom$X13[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "perfeito"), 1, 0)
  db_dummy_bom$X14[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "adorei"), 1, 0)
  db_dummy_bom$X15[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "recomendo"), 1, 0)
  db_dummy_bom$X16[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "bem"), 1, 0)
  db_dummy_bom$X17[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "rápido"), 1, 0)
  db_dummy_bom$X18[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "recebi"), 1, 0)
  db_dummy_bom$X19[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "excelente"), 1, 0)
  db_dummy_bom$X20[i] <-
    ifelse(str_detect(db_dummy_bom$comp_comment[i], "parabéns"), 1, 0)

}

db_train_bom <- db_dummy_bom[index, 8:28]
db_test_bom <- db_dummy_bom[-index, 8:28]
```

--------------------------------------------------------------------------------

```{r model log BOM}
log_fit_bom <- glm(Y ~ .,
                   data = db_train_bom,
                   family = "binomial")

# summary(log_fit_bom)

db_test_log_bom <- db_test_bom

log_pred_bom <- predict(log_fit_bom, newdata = db_test_log_bom, type = "response")
db_test_log_bom$pred <- log_pred_bom
db_test_log_bom$pred.class <- ifelse(log_pred_bom > 0.5,1,0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_log_bom <- table(as.numeric(db_test_log_bom$pred.class), db_test_log_bom$Y)

acc_log_bom <- sum(ctable_log_bom[1,1], ctable_log_bom[2,2]) / sum(ctable_log_bom)

esp_log_bom <- ctable_log_bom[1,1] / sum(ctable_log_bom[,1])

sen_log_bom <- ctable_log_bom[2,2] / sum(ctable_log_bom[,2])

roc_log_bom <- roc(db_test_log_bom$Y, db_test_log_bom$pred)
print(roc_log_bom)

plot(roc_log_bom)
plot(smooth(roc_log_bom), add=T, col="blue")

smooth(roc_log_bom)$auc
as.numeric(smooth(roc_log_bom)$auc)

with(roc_log_bom, plot(sensitivities ~ thresholds, type="l", col="blue"))
with(roc_log_bom, lines(specificities ~ thresholds, col="red", lty=2))
```

```{r model ptk BOM}
ptk_fit_bom <- ctree(Y ~ .,
                   data = db_train_bom)

# summary(ptk_fit_bom)

db_test_ptk_bom <- db_test_bom

db_test_ptk_bom$pred <- predict(ptk_fit_bom, newdata = db_test_ptk_bom)
db_test_ptk_bom$pred.class <- ifelse(db_test_ptk_bom$pred > 0.5,1,0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_ptk_bom <- table(as.numeric(db_test_ptk_bom$pred.class), db_test_ptk_bom$Y)

acc_ptk_bom <- sum(ctable_ptk_bom[1,1], ctable_ptk_bom[2,2]) / sum(ctable_ptk_bom)

esp_ptk_bom <- ctable_ptk_bom[1,1] / sum(ctable_ptk_bom[,1])

sen_ptk_bom <- ctable_ptk_bom[2,2] / sum(ctable_ptk_bom[,2])
```

```{r model rnf BOM}
rnf_fit_bom <- randomForest(as.factor(Y) ~ .,
                            data = db_train_bom)

# summary(rnf_fit_bom)

db_test_rnf_bom <- db_test_bom

db_test_rnf_bom$pred <- predict(rnf_fit_bom, newdata = db_test_rnf_bom, type = "response")

# MATRIZ DE CONFUSAO E METRICAS
ctable_rnf_bom <- table(as.numeric(db_test_rnf_bom$pred), db_test_rnf_bom$Y)

acc_rnf_bom <- sum(ctable_rnf_bom[1,1], ctable_rnf_bom[2,2]) / sum(ctable_rnf_bom)

esp_rnf_bom <- ctable_rnf_bom[1,1] / sum(ctable_rnf_bom[,1])

sen_rnf_bom <- ctable_rnf_bom[2,2] / sum(ctable_rnf_bom[,2])
```

```{r model xgb BOM}
db_train_xgb_bom_X <- as.matrix(db_train_bom[,2:21])
db_train_xgb_bom_Y <- db_train_bom[,1]
db_test_xgb_bom_X <- db_test_bom[,2:21]

xgb_fit_bom <- xgboost(data  = db_train_xgb_bom_X,
                       label = db_train_xgb_bom_Y,
                       nrounds = 10,
                       objective ="binary:logistic")

# summary(xgb_fit_bom)

db_test_xgb_bom_X$pred <- predict(xgb_fit_bom, newdata = as.matrix(db_test_xgb_bom_X))

db_test_xgb_bom_X$pred.class <- ifelse(db_test_xgb_bom_X$pred > 0.5, 1, 0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_xgb_bom <- table(as.numeric(db_test_xgb_bom_X$pred.class), db_test_bom[,1])

acc_xgb_bom <- sum(ctable_xgb_bom[1,1], ctable_xgb_bom[2,2]) / sum(ctable_xgb_bom)

esp_xgb_bom <- ctable_xgb_bom[1,1] / sum(ctable_xgb_bom[,1])

sen_xgb_bom <- ctable_xgb_bom[2,2] / sum(ctable_xgb_bom[,2])
```

```{r model nba BOM}
nba_fit_bom <- naiveBayes(Y ~ ., data = db_train_bom)

db_test_nba_bom <- db_test_bom

db_test_nba_bom$pred <- predict(nba_fit_bom, newdata = db_test_nba_bom)

# MATRIZ DE CONFUSAO E METRICAS
ctable_nba_bom <- table(db_test_nba_bom$pred, db_test_nba_bom$Y)

acc_nba_bom <- sum(ctable_nba_bom[1,1], ctable_nba_bom[2,2]) / sum(ctable_nba_bom)

esp_nba_bom <- ctable_nba_bom[1,1] / sum(ctable_nba_bom[,1])

sen_nba_bom <- ctable_nba_bom[2,2] / sum(ctable_nba_bom[,2])
```



```{r wordcloud NAO BOM}
db_wc_nbom <- wc_db_clean[index,] %>%
  filter(review_score <= 3)

corpus_wc_nbom <- Corpus(VectorSource(db_wc_nbom[,2])) %>%
  tm_map(removeWords, stopwords("portuguese")) %>%
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(content_transformer(tolower))

tdm <- TermDocumentMatrix(corpus_wc_nbom)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)

set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
          max.words=20, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
```

```{r dummy variables NAO BOM}
db_dummy_nbom <- wc_db_clean

str(db_dummy_nbom$comp_comment)


for (i in 1:nrow(db_dummy_nbom)) {
  
# CRIACAO DA VARIAVEL RESPOSTA (Y)
  db_dummy_nbom$Y5[i] <- if_else(db_dummy_nbom$review_score[i] == 5, 0, 0)
  db_dummy_nbom$Y4[i] <- if_else(db_dummy_nbom$review_score[i] == 4, 0, 0)
  db_dummy_nbom$Y3[i] <- if_else(db_dummy_nbom$review_score[i] == 3, 1, 0)
  db_dummy_nbom$Y2[i] <- if_else(db_dummy_nbom$review_score[i] == 2, 1, 0)
  db_dummy_nbom$Y1[i] <- if_else(db_dummy_nbom$review_score[i] == 1, 1, 0)
  
  db_dummy_nbom$Y[i] <- 
    db_dummy_nbom$Y5[i] +
    db_dummy_nbom$Y4[i] +
    db_dummy_nbom$Y3[i] +
    db_dummy_nbom$Y2[i] + 
    db_dummy_nbom$Y1[i]
  
# CRIACAO DAS VARIAVEIS DUMMIES
  db_dummy_nbom$X1[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "contato"), 1, 0)
  db_dummy_nbom$X2[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "porém"), 1, 0)
  db_dummy_nbom$X3[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "nada"), 1, 0)
  db_dummy_nbom$X4[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "recomendo"), 1, 0)
  db_dummy_nbom$X5[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "comprei"), 1, 0)
  db_dummy_nbom$X6[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "gostei"), 1, 0)
  db_dummy_nbom$X7[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "não"), 1, 0)
  db_dummy_nbom$X8[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "outro"), 1, 0)
  db_dummy_nbom$X9[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "quero"), 1, 0)
  db_dummy_nbom$X10[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "pedido"), 1, 0)
  db_dummy_nbom$X11[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "bom"), 1, 0)
  db_dummy_nbom$X12[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "qualidade"), 1, 0)
  db_dummy_nbom$X13[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "recebi"), 1, 0)
  db_dummy_nbom$X14[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "agora"), 1, 0)
  db_dummy_nbom$X15[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "estou"), 1, 0)
  db_dummy_nbom$X16[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "ainda"), 1, 0)
  db_dummy_nbom$X17[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "dias"), 1, 0)
  db_dummy_nbom$X18[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "apenas"), 1, 0)
  db_dummy_nbom$X19[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "correios"), 1, 0)
  db_dummy_nbom$X20[i] <-
    ifelse(str_detect(db_dummy_nbom$comp_comment[i], "aguardando"), 1, 0)

}

db_train_nbom <- db_dummy_nbom[index, 8:28]
db_test_nbom <- db_dummy_nbom[-index, 8:28]
```

```{r model log NAO BOM}
log_fit_nbom <- glm(Y ~ .,
                   data = db_train_nbom,
                   family = "binomial")

# summary(log_fit_nbom)

db_test_log_nbom <- db_test_nbom

log_pred_nbom <- predict(log_fit_nbom, newdata = db_test_log_nbom, type = "response")
db_test_log_nbom$pred <- log_pred_nbom
db_test_log_nbom$pred.class <- ifelse(log_pred_nbom > 0.5,1,0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_log_nbom <- table(as.numeric(db_test_log_nbom$pred.class), db_test_log_nbom$Y)

acc_log_nbom <- sum(ctable_log_nbom[1,1], ctable_log_nbom[2,2]) / sum(ctable_log_nbom)

esp_log_nbom <- ctable_log_nbom[1,1] / sum(ctable_log_nbom[,1])

sen_log_nbom <- ctable_log_nbom[2,2] / sum(ctable_log_nbom[,2])

roc_log_nbom <- roc(db_test_log_nbom$Y, db_test_log_nbom$pred)
print(roc_log_nbom)

plot(roc_log_nbom)
plot(smooth(roc_log_nbom), add=T, col="blue")

smooth(roc_log_nbom)$auc
as.numeric(smooth(roc_log_nbom)$auc)

with(roc_log_nbom, plot(sensitivities ~ thresholds, type="l", col="blue"))
with(roc_log_nbom, lines(specificities ~ thresholds, col="red", lty=2))
```

```{r model ptk NAO BOM}
ptk_fit_nbom <- ctree(Y ~ .,
                   data = db_train_nbom)

# summary(ptk_fit_nbom)

db_test_ptk_nbom <- db_test_nbom

db_test_ptk_nbom$pred <- predict(ptk_fit_nbom, newdata = db_test_ptk_nbom)
db_test_ptk_nbom$pred.class <- ifelse(db_test_ptk_nbom$pred > 0.5,1,0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_ptk_nbom <- table(as.numeric(db_test_ptk_nbom$pred.class), db_test_ptk_nbom$Y)

acc_ptk_nbom <- sum(ctable_ptk_nbom[1,1], ctable_ptk_nbom[2,2]) / sum(ctable_ptk_nbom)

esp_ptk_nbom <- ctable_ptk_nbom[1,1] / sum(ctable_ptk_nbom[,1])

sen_ptk_nbom <- ctable_ptk_nbom[2,2] / sum(ctable_ptk_nbom[,2])
```

```{r model rnf NAO BOM}
rnf_fit_nbom <- randomForest(as.factor(Y) ~ .,
                            data = db_train_nbom)

# summary(rnf_fit_nbom)

db_test_rnf_nbom <- db_test_nbom

db_test_rnf_nbom$pred <- predict(rnf_fit_nbom, newdata = db_test_rnf_nbom, type = "response")

# MATRIZ DE CONFUSAO E METRICAS
ctable_rnf_nbom <- table(as.numeric(db_test_rnf_nbom$pred), db_test_rnf_nbom$Y)

acc_rnf_nbom <- sum(ctable_rnf_nbom[1,1], ctable_rnf_nbom[2,2]) / sum(ctable_rnf_nbom)

esp_rnf_nbom <- ctable_rnf_nbom[1,1] / sum(ctable_rnf_nbom[,1])

sen_rnf_nbom <- ctable_rnf_nbom[2,2] / sum(ctable_rnf_nbom[,2])
```

```{r model xgb NAO BOM}
db_train_xgb_nbom_X <- as.matrix(db_train_nbom[,2:21])
db_train_xgb_nbom_Y <- db_train_nbom[,1]
db_test_xgb_nbom_X <- db_test_nbom[,2:21]

xgb_fit_nbom <- xgboost(data  = db_train_xgb_nbom_X,
                       label = db_train_xgb_nbom_Y,
                       nrounds = 10,
                       objective ="binary:logistic")

# summary(xgb_fit_nbom)

db_test_xgb_nbom_X$pred <- predict(xgb_fit_nbom, newdata = as.matrix(db_test_xgb_nbom_X))

db_test_xgb_nbom_X$pred.class <- ifelse(db_test_xgb_nbom_X$pred > 0.5, 1, 0)

# MATRIZ DE CONFUSAO E METRICAS
ctable_xgb_nbom <- table(as.numeric(db_test_xgb_nbom_X$pred.class), db_test_nbom[,1])

acc_xgb_nbom <- sum(ctable_xgb_nbom[1,1], ctable_xgb_nbom[2,2]) / sum(ctable_xgb_nbom)

esp_xgb_nbom <- ctable_xgb_nbom[1,1] / sum(ctable_xgb_nbom[,1])

sen_xgb_nbom <- ctable_xgb_nbom[2,2] / sum(ctable_xgb_nbom[,2])
```

```{r model nba NAO BOM}
nba_fit_nbom <- naiveBayes(Y ~ ., data = db_train_nbom)

db_test_nba_nbom <- db_test_nbom

db_test_nba_nbom$pred <- predict(nba_fit_nbom, newdata = db_test_nba_nbom)

# MATRIZ DE CONFUSAO E METRICAS
ctable_nba_nbom <- table(db_test_nba_nbom$pred, db_test_nba_nbom$Y)

acc_nba_nbom <- sum(ctable_nba_nbom[1,1], ctable_nba_nbom[2,2]) / sum(ctable_nba_nbom)

esp_nba_nbom <- ctable_nba_nbom[1,1] / sum(ctable_nba_nbom[,1])

sen_nba_nbom <- ctable_nba_nbom[2,2] / sum(ctable_nba_nbom[,2])
```

```{r model comparison table}
model_comp_table <- data.frame(Modelo = c("Logístico", "Árvore de regressão",
                                          "Random Forest", "XGBoost", "Naive Bayes",
                                          "Logístico", "Árvore de regressão",
                                          "Random Forest", "XGBoost", "Naive Bayes"),
                               Tipo = c("Bom", "Bom", "Bom", "Bom", "Bom",
                                        "Não bom", "Não bom", "Não bom", "Não bom", "Não bom"),
                               Acurácia = c(acc_log_bom, acc_ptk_bom, acc_rnf_bom,
                                            acc_xgb_bom, acc_nba_bom, acc_log_nbom,
                                            acc_ptk_nbom, acc_rnf_nbom, acc_xgb_nbom,
                                            acc_nba_nbom),
                               Especificidade = c(esp_log_bom, esp_ptk_bom, esp_rnf_bom,
                                                  esp_xgb_bom, esp_nba_bom, esp_log_nbom,
                                                  esp_ptk_nbom, esp_rnf_nbom, esp_xgb_nbom,
                                                  esp_nba_nbom),
                               Sensibilidade = c(sen_log_bom, sen_ptk_bom, sen_rnf_bom,
                                                 sen_xgb_bom, sen_nba_bom, sen_log_nbom,
                                                 sen_ptk_nbom, sen_rnf_nbom, sen_xgb_nbom,
                                                 sen_nba_nbom))
```



```{r estimativa de pontuacao por palavra}
# cria função de moda
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Tokeniza num dataset de palavras, média, mediana, moda, var e dev pad.
# O dataset não possui observações com var = NA ou 0 ou <= 2.
# Ou seja, não possui palavras que apareçam apenas uma vez ou que apareçam
# tanto em comentários com notas altas como baixas, pois não contribuem
# para a determinação da nota.
word_evaluation <- wc_db_clean %>%
  unnest_tokens(output = "Palavras",
                input = comp_comment,
                token = "words") %>%
  group_by(Palavras) %>%
  summarise(avg_pt = mean(review_score), #"força" positiva ou negativa da palavra - fazer um diag. de dispersão kn-n, agrupar as palavras
            median_pt = median(review_score),
            mode_pt = as.double(getmode(review_score)),
            var_pt = var(review_score),
            dev_pt = sd(review_score)) %>%
  na.omit() %>%
  filter(var_pt < 2 & var_pt != 0) #revisar essa decisão de var <= 2 (foi arbitrário)

# quantas palavras são necessárias para definir uma nota? 
 
```


